{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Textual Data in Lily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as rd\n",
    "import re\n",
    "import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Panellid</th>\n",
       "      <th>E-mailadres</th>\n",
       "      <th>Achternaam</th>\n",
       "      <th>Voornaam</th>\n",
       "      <th>Taal</th>\n",
       "      <th>Geslacht</th>\n",
       "      <th>Geboortedatum</th>\n",
       "      <th>Veld 1</th>\n",
       "      <th>Veld 5</th>\n",
       "      <th>Straat</th>\n",
       "      <th>...</th>\n",
       "      <th>6.4. onze website</th>\n",
       "      <th>7.1. Naamsbekendheid</th>\n",
       "      <th>7.2. Prijs</th>\n",
       "      <th>7.3. Contact met de klantendienst</th>\n",
       "      <th>7.4. Groene energie</th>\n",
       "      <th>7.5. Advies vrienden, familie, collega's</th>\n",
       "      <th>7.6. Duidelijkheid en correctheid facturen</th>\n",
       "      <th>7.7. Other</th>\n",
       "      <th>7.7. Ander, gelieve te specificeren</th>\n",
       "      <th>prijskwaliteit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Respondent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>35855057</td>\n",
       "      <td>gaston@f-a-q.be</td>\n",
       "      <td>Gaston Verelst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nl</td>\n",
       "      <td>Man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150153215.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Groenstraat</td>\n",
       "      <td>...</td>\n",
       "      <td>NVT</td>\n",
       "      <td>Niet belangrijk</td>\n",
       "      <td>Uiterst belangrijk</td>\n",
       "      <td>Belangrijk</td>\n",
       "      <td>Niet belangrijk</td>\n",
       "      <td>Niet belangrijk</td>\n",
       "      <td>Uiterst belangrijk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>35855871</td>\n",
       "      <td>familiewilms@hotmail.com</td>\n",
       "      <td>Wilhelmus Wilms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nl</td>\n",
       "      <td>Man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150346421.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Koekoeklaan</td>\n",
       "      <td>...</td>\n",
       "      <td>NVT</td>\n",
       "      <td>Niet belangrijk</td>\n",
       "      <td>Zeer belangrijk</td>\n",
       "      <td>Niet belangrijk</td>\n",
       "      <td>Niet belangrijk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belangrijk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>35855594</td>\n",
       "      <td>doke.brouns@telenet.be</td>\n",
       "      <td>Doke Brouns</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nl</td>\n",
       "      <td>Vrouw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150136365.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steenberg</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Niet belangrijk</td>\n",
       "      <td>Uiterst belangrijk</td>\n",
       "      <td>Belangrijk</td>\n",
       "      <td>Belangrijk</td>\n",
       "      <td>Belangrijk</td>\n",
       "      <td>Zeer belangrijk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Panellid               E-mailadres       Achternaam Voornaam Taal  \\\n",
       "Respondent                                                                      \n",
       "10398       35855057           gaston@f-a-q.be   Gaston Verelst      NaN   nl   \n",
       "10399       35855871  familiewilms@hotmail.com  Wilhelmus Wilms      NaN   nl   \n",
       "10400       35855594    doke.brouns@telenet.be      Doke Brouns      NaN   nl   \n",
       "\n",
       "           Geslacht Geboortedatum       Veld 1 Veld 5       Straat  \\\n",
       "Respondent                                                           \n",
       "10398           Man           NaN  150153215.0    NaN  Groenstraat   \n",
       "10399           Man           NaN  150346421.0    NaN  Koekoeklaan   \n",
       "10400         Vrouw           NaN  150136365.0    NaN    Steenberg   \n",
       "\n",
       "                ...       6.4. onze website 7.1. Naamsbekendheid  \\\n",
       "Respondent      ...                                                \n",
       "10398           ...                     NVT      Niet belangrijk   \n",
       "10399           ...                     NVT      Niet belangrijk   \n",
       "10400           ...                       6      Niet belangrijk   \n",
       "\n",
       "                    7.2. Prijs  7.3. Contact met de klantendienst  \\\n",
       "Respondent                                                          \n",
       "10398       Uiterst belangrijk                         Belangrijk   \n",
       "10399          Zeer belangrijk                    Niet belangrijk   \n",
       "10400       Uiterst belangrijk                         Belangrijk   \n",
       "\n",
       "           7.4. Groene energie 7.5. Advies vrienden, familie, collega's  \\\n",
       "Respondent                                                                \n",
       "10398          Niet belangrijk                          Niet belangrijk   \n",
       "10399          Niet belangrijk                                      NaN   \n",
       "10400               Belangrijk                               Belangrijk   \n",
       "\n",
       "            7.6. Duidelijkheid en correctheid facturen 7.7. Other  \\\n",
       "Respondent                                                          \n",
       "10398                               Uiterst belangrijk        NaN   \n",
       "10399                                       Belangrijk        NaN   \n",
       "10400                                  Zeer belangrijk        NaN   \n",
       "\n",
       "           7.7. Ander, gelieve te specificeren prijskwaliteit  \n",
       "Respondent                                                     \n",
       "10398                                      NaN            8.0  \n",
       "10399                                      NaN            4.0  \n",
       "10400                                      NaN            3.0  \n",
       "\n",
       "[3 rows x 52 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('/Users/desiredewaele/Google Drive/Datasets/lily text.xlsx', index_col=0)\n",
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "## Data Preproccessing\n",
    "\n",
    "---\n",
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = data.iloc[:,31:35]\n",
    "data.columns = ['label', 'text1', 'text2', 'text3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>text3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Respondent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10396</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lagere prijzen ???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>6</td>\n",
       "      <td>Ik denk niet dat Essent beter of slechter is d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>5</td>\n",
       "      <td>rekening even hoog als bij vorige leverancier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>5</td>\n",
       "      <td>Duur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                              text1 text2  \\\n",
       "Respondent                                                                   \n",
       "10396           7                                                NaN   NaN   \n",
       "10397           8                                                NaN   NaN   \n",
       "10398           6  Ik denk niet dat Essent beter of slechter is d...   NaN   \n",
       "10399           5      rekening even hoog als bij vorige leverancier   NaN   \n",
       "10400           5                                               Duur   NaN   \n",
       "\n",
       "                         text3  \n",
       "Respondent                      \n",
       "10396                      NaN  \n",
       "10397       lagere prijzen ???  \n",
       "10398                      NaN  \n",
       "10399                      NaN  \n",
       "10400                      NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "### Feature Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data.text1 = data.text1.apply(lambda x: x.encode('utf8') if isinstance(x, unicode) else ' ')\n",
    "data.text2 = data.text2.apply(lambda x: x.encode('utf8') if isinstance(x, unicode) else ' ')\n",
    "data.text3 = data.text3.apply(lambda x: x.encode('utf8') if isinstance(x, unicode) else ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data['text'] = data.text1.str.cat(data.text2).str.cat(data.text3)\n",
    "data = data[['label', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def textconverter(text):\n",
    "    text = text.lower()                      # Change text to lowercase\n",
    "    text = re.sub('[^(a-z)]| ', ' ', text)   # Change all not-text to spaces\n",
    "    text = re.sub(' +',' ',text)             # Remove all redundant spaces\n",
    "    text = text.strip()                      # Remove outer whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Respondent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10396</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>8</td>\n",
       "      <td>lagere prijzen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>6</td>\n",
       "      <td>ik denk niet dat essent beter of slechter is d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>5</td>\n",
       "      <td>rekening even hoog als bij vorige leverancier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>5</td>\n",
       "      <td>duur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                               text\n",
       "Respondent                                                          \n",
       "10396           7                                                   \n",
       "10397           8                                     lagere prijzen\n",
       "10398           6  ik denk niet dat essent beter of slechter is d...\n",
       "10399           5      rekening even hoog als bij vorige leverancier\n",
       "10400           5                                               duur"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text = data.text.apply(lambda x: textconverter(x))\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Respondent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10395</th>\n",
       "      <td>5</td>\n",
       "      <td>er</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>8</td>\n",
       "      <td>lagere prijzen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>6</td>\n",
       "      <td>ik denk niet dat essent beter of slechter is d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>5</td>\n",
       "      <td>rekening even hoog als bij vorige leverancier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>5</td>\n",
       "      <td>duur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                               text\n",
       "Respondent                                                          \n",
       "10395           5                                                 er\n",
       "10397           8                                     lagere prijzen\n",
       "10398           6  ik denk niet dat essent beter of slechter is d...\n",
       "10399           5      rekening even hoog als bij vorige leverancier\n",
       "10400           5                                               duur"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data.text != '']\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6523"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "### Label Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3248\n",
      "3275\n"
     ]
    }
   ],
   "source": [
    "print(len(data[data.label > 7]))\n",
    "print(len(data[data.label <= 7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Respondent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10395</th>\n",
       "      <td>0</td>\n",
       "      <td>er</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>1</td>\n",
       "      <td>lagere prijzen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>0</td>\n",
       "      <td>ik denk niet dat essent beter of slechter is d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>0</td>\n",
       "      <td>rekening even hoog als bij vorige leverancier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>0</td>\n",
       "      <td>duur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                               text\n",
       "Respondent                                                          \n",
       "10395           0                                                 er\n",
       "10397           1                                     lagere prijzen\n",
       "10398           0  ik denk niet dat essent beter of slechter is d...\n",
       "10399           0      rekening even hoog als bij vorige leverancier\n",
       "10400           0                                               duur"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label = data.label.apply(lambda x: 1 if x > 7 else 0)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "## Save Tidy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('/Users/desiredewaele/Google Drive/Datasets/lilyTidyText.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "## Get Word Counts & Tfidfs with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "a = CountVectorizer()\n",
    "b = CountVectorizer(ngram_range=(1, 2))\n",
    "c = CountVectorizer(ngram_range=(1, 3))\n",
    "d = TfidfVectorizer(sublinear_tf=True)\n",
    "e = TfidfVectorizer(sublinear_tf=True, ngram_range=(1,3))\n",
    "f = TfidfVectorizer(sublinear_tf=True, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "onegrams = pd.DataFrame(a.fit_transform(data.text).toarray(), columns=a.get_feature_names())\n",
    "twograms = pd.DataFrame(b.fit_transform(data.text).toarray(), columns=b.get_feature_names())\n",
    "trigrams = pd.DataFrame(c.fit_transform(data.text).toarray(), columns=c.get_feature_names())\n",
    "onetfidf = pd.DataFrame(d.fit_transform(data.text).toarray(), columns=d.get_feature_names())\n",
    "twotfidf = pd.DataFrame(e.fit_transform(data.text).toarray(), columns=e.get_feature_names())\n",
    "tritfidf = pd.DataFrame(f.fit_transform(data.text).toarray(), columns=f.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aagesloten</th>\n",
       "      <th>aagesloten via</th>\n",
       "      <th>aagesloten via groepsaankoop</th>\n",
       "      <th>aan</th>\n",
       "      <th>aan als</th>\n",
       "      <th>aan als de</th>\n",
       "      <th>aan andere</th>\n",
       "      <th>aan andere dat</th>\n",
       "      <th>aan anderen</th>\n",
       "      <th>aan anderen hoeft</th>\n",
       "      <th>...</th>\n",
       "      <th>zwart op</th>\n",
       "      <th>zwart op wit</th>\n",
       "      <th>zweem</th>\n",
       "      <th>zweem van</th>\n",
       "      <th>zweem van onbereikbaarheid</th>\n",
       "      <th>zyn</th>\n",
       "      <th>zyn ben</th>\n",
       "      <th>zyn ben aant</th>\n",
       "      <th>zyn voor</th>\n",
       "      <th>zyn voor nieuwe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6519</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6520</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6521</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6522</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108975 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aagesloten  aagesloten via  aagesloten via groepsaankoop  aan  aan als  \\\n",
       "6518         0.0             0.0                           0.0  0.0      0.0   \n",
       "6519         0.0             0.0                           0.0  0.0      0.0   \n",
       "6520         0.0             0.0                           0.0  0.0      0.0   \n",
       "6521         0.0             0.0                           0.0  0.0      0.0   \n",
       "6522         0.0             0.0                           0.0  0.0      0.0   \n",
       "\n",
       "      aan als de  aan andere  aan andere dat  aan anderen  aan anderen hoeft  \\\n",
       "6518         0.0         0.0             0.0          0.0                0.0   \n",
       "6519         0.0         0.0             0.0          0.0                0.0   \n",
       "6520         0.0         0.0             0.0          0.0                0.0   \n",
       "6521         0.0         0.0             0.0          0.0                0.0   \n",
       "6522         0.0         0.0             0.0          0.0                0.0   \n",
       "\n",
       "           ...         zwart op  zwart op wit  zweem  zweem van  \\\n",
       "6518       ...              0.0           0.0    0.0        0.0   \n",
       "6519       ...              0.0           0.0    0.0        0.0   \n",
       "6520       ...              0.0           0.0    0.0        0.0   \n",
       "6521       ...              0.0           0.0    0.0        0.0   \n",
       "6522       ...              0.0           0.0    0.0        0.0   \n",
       "\n",
       "      zweem van onbereikbaarheid  zyn  zyn ben  zyn ben aant  zyn voor  \\\n",
       "6518                         0.0  0.0      0.0           0.0       0.0   \n",
       "6519                         0.0  0.0      0.0           0.0       0.0   \n",
       "6520                         0.0  0.0      0.0           0.0       0.0   \n",
       "6521                         0.0  0.0      0.0           0.0       0.0   \n",
       "6522                         0.0  0.0      0.0           0.0       0.0   \n",
       "\n",
       "      zyn voor nieuwe  \n",
       "6518              0.0  \n",
       "6519              0.0  \n",
       "6520              0.0  \n",
       "6521              0.0  \n",
       "6522              0.0  \n",
       "\n",
       "[5 rows x 108975 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tritfidf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getTopValues(s):\n",
    "    tmp = s.sort_values(ascending=False)[:3]\n",
    "    return tuple(tmp.index) #dict(zip(tmp.index, tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6518       (er, zyn, fiabilit)\n",
       "6519    (prijzen, lagere, zyn)\n",
       "6520        (essent, niet, de)\n",
       "6521    (even, hoog, rekening)\n",
       "6522     (duur, zyn, fiabilit)\n",
       "dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onegrams.apply(getTopValues, axis=1).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, validX, trainY, validY = train_test_split(tritfidf.as_matrix(), data.label, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "lr = LogisticRegression()         # Logistic Regression\n",
    "nb = GaussianNB()                 # Gaussian Naive Bayes\n",
    "sd = SGDClassifier()              # Stochastic Gradient Descent\n",
    "dt = DecisionTreeClassifier()     # Decision Tree\n",
    "ft = RandomForestClassifier()     # Random Forrest Tree\n",
    "et = ExtraTreesClassifier()       # Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.706693919264\n",
      "0.922251423565\n"
     ]
    }
   ],
   "source": [
    "print(lr.score(validX, validY))\n",
    "print(lr.score(trainX, trainY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Respondent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>0</td>\n",
       "      <td>geen zoomit betalingen mogelijk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>1</td>\n",
       "      <td>prix competitifs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8625</th>\n",
       "      <td>1</td>\n",
       "      <td>systheme de facturation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>1</td>\n",
       "      <td>niet alleen actie s doen naar nieuwe klanten t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6107</th>\n",
       "      <td>0</td>\n",
       "      <td>vous avez deja vu le temps que lon perd chez v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6411</th>\n",
       "      <td>1</td>\n",
       "      <td>tr s bon service rien redire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>1</td>\n",
       "      <td>als goedkoopste voor mij bij groepsaankoop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3636</th>\n",
       "      <td>0</td>\n",
       "      <td>verwarrende communicatie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>0</td>\n",
       "      <td>geen reden waarom wel essent spring er niet uit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>de goedkoopste blijven</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                               text  \\\n",
       "Respondent                                                             \n",
       "2042            0                    geen zoomit betalingen mogelijk   \n",
       "5941            1                                   prix competitifs   \n",
       "8625            1                            systheme de facturation   \n",
       "1058            1  niet alleen actie s doen naar nieuwe klanten t...   \n",
       "6107            0  vous avez deja vu le temps que lon perd chez v...   \n",
       "6411            1                       tr s bon service rien redire   \n",
       "3981            1         als goedkoopste voor mij bij groepsaankoop   \n",
       "3636            0                           verwarrende communicatie   \n",
       "2041            0    geen reden waarom wel essent spring er niet uit   \n",
       "200             0                             de goedkoopste blijven   \n",
       "\n",
       "            prediction  \n",
       "Respondent              \n",
       "2042                 0  \n",
       "5941                 1  \n",
       "8625                 0  \n",
       "1058                 0  \n",
       "6107                 0  \n",
       "6411                 1  \n",
       "3981                 1  \n",
       "3636                 0  \n",
       "2041                 0  \n",
       "200                  0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = data.loc[validY[:10].index]\n",
    "predictions['prediction'] = lr.predict(validX[:10])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "import math\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6523\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "text = sum(list(data.text.apply(lambda x: x.split())), [])\n",
    "print(len(data))\n",
    "print(len(set(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "VOCAB = 5000\n",
    "EMBED = 128\n",
    "\n",
    "embeddings = tf.Variable(tf.random_uniform([VOCAB, EMBED], -1.0, 1.0))\n",
    "w = tf.Variable(tf.truncated_normal([VOCAB, EMBED], stddev=1.0 / math.sqrt(EMBED)))\n",
    "b = tf.Variable(tf.zeros([VOCAB]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Most common words:', [['UNK', 1], (1, 3775), (0, 3188), (2, 1346), (3, 1331)])\n",
      "('Sample data', [2, 71, 1918, 910, 483, 2, 183, 123, 287, 57], [0, 70, 1917, 909, 482, 0, 182, 122, 286, 56])\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(words):\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(VOCAB - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reverse_dictionary\n",
    "\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(text)\n",
    "print('Most common words:', count[:5])\n",
    "print('Sample data', data[:10], [reverse_dictionary[i] for i in data[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data:', [0, 70, 1917, 909, 482, 0, 182, 122])\n",
      "\n",
      "with num_skips = 2 and skip_window = 1:\n",
      "('    batch:', [70, 70, 1917, 1917, 909, 909, 482, 482])\n",
      "('    labels:', [1917, 0, 909, 70, 482, 1917, 909, 0])\n",
      "\n",
      "with num_skips = 4 and skip_window = 2:\n",
      "('    batch:', [1917, 1917, 1917, 1917, 909, 909, 909, 909])\n",
      "('    labels:', [0, 70, 482, 909, 70, 0, 1917, 482])\n"
     ]
    }
   ],
   "source": [
    "data_index = 0\n",
    "\n",
    "def generate_batch(batch_size, num_skips, skip_window):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1 # [ skip_window target skip_window ]\n",
    "    buffer = collections.deque(maxlen=span)\n",
    "    for _ in range(span):\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    for i in range(batch_size // num_skips):\n",
    "        target = skip_window  # target label at the center of the buffer\n",
    "        targets_to_avoid = [ skip_window ]\n",
    "        for j in range(num_skips):\n",
    "            while target in targets_to_avoid:\n",
    "                target = random.randint(0, span - 1)\n",
    "            targets_to_avoid.append(target)\n",
    "            batch[i * num_skips + j] = buffer[skip_window]\n",
    "            labels[i * num_skips + j, 0] = buffer[target]\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    return batch, labels\n",
    "\n",
    "print('data:', [reverse_dictionary[di] for di in data[:8]])\n",
    "\n",
    "for SKIPS, WINDOW in [(2, 1), (4, 2)]:\n",
    "    data_index = 0\n",
    "    batch, labels = generate_batch(batch_size=8, num_skips=SKIPS, skip_window=WINDOW)\n",
    "    print('\\nwith num_skips = %d and skip_window = %d:' % (SKIPS, WINDOW))\n",
    "    print('    batch:', [reverse_dictionary[bi] for bi in batch])\n",
    "    print('    labels:', [reverse_dictionary[li] for li in labels.reshape(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BATCH = 128\n",
    "EMBED = 128 # Dimension of the embedding vector.\n",
    "WINDOW = 1 # How many words to consider left and right.\n",
    "SKIPS = 2 # How many times to reuse an input to generate a label.\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors. Here we limit the validation samples \n",
    "# to the words that have a low numeric ID, which by construction are also the most frequent. \n",
    "valid_size = 8 # Random set of words to evaluate similarity on.\n",
    "valid_window = 100 # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.array(random.sample(range(valid_window), valid_size))\n",
    "num_sampled = 64 # Number of negative examples to sample.\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(), tf.device('/cpu:0'):\n",
    "\n",
    "    # Input data.\n",
    "    tfTrainX = tf.placeholder(tf.int32, shape=[BATCH])\n",
    "    tfTrainY = tf.placeholder(tf.int32, shape=[BATCH, 1])\n",
    "    tfValidX = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "    # Variables.\n",
    "    embeddings = tf.Variable(tf.random_uniform([vocabulary_size, EMBED], -1.0, 1.0))\n",
    "    softmax_weights = tf.Variable(tf.truncated_normal(\n",
    "        [vocabulary_size, embedding_size], stddev=1.0 / math.sqrt(EMBED)))\n",
    "    softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "    # Model.\n",
    "    # Look up embeddings for inputs.\n",
    "    embed = tf.nn.embedding_lookup(embeddings, train_dataset)\n",
    "    # Compute the softmax loss, using a sample of the negative labels each time.\n",
    "    loss = tf.reduce_mean(tf.nn.sampled_softmax_loss(\n",
    "        weights=softmax_weights, biases=softmax_biases, inputs=embed, \n",
    "        labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size))\n",
    "\n",
    "    # Optimizer.\n",
    "    # Note: The optimizer will optimize the softmax_weights AND the embeddings.\n",
    "    # This is because the embeddings are defined as a variable quantity and the\n",
    "    # optimizer's `minimize` method will by default modify all variable quantities \n",
    "    # that contribute to the tensor it is passed.\n",
    "    # See docs on `tf.train.Optimizer.minimize()` for more details.\n",
    "    optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)\n",
    "\n",
    "    # Compute the similarity between minibatch examples and all embeddings.\n",
    "    # We use the cosine distance:\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "    similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_steps = 100001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    average_loss = 0\n",
    "    for step in range(num_steps):\n",
    "        batch_data, batch_labels = generate_batch(batch_size, num_skips, skip_window)\n",
    "        feed = {train_dataset : batch_data, train_labels : batch_labels}\n",
    "        _, l = session.run([optimizer, loss], feed_dict=feed)\n",
    "        average_loss += l\n",
    "        if step % 2000 == 0:\n",
    "            if step > 0:\n",
    "                average_loss = average_loss / 2000\n",
    "            # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "            print('Average loss at step %d: %f' % (step, average_loss))\n",
    "            average_loss = 0\n",
    "        # note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "        if step % 10000 == 0:\n",
    "            sim = similarity.eval()\n",
    "            for i in range(valid_size):\n",
    "                valid_word = reverse_dictionary[valid_examples[i]]\n",
    "                top_k = 8 # number of nearest neighbors\n",
    "                nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
    "                log = 'Nearest to %s:' % valid_word\n",
    "                for k in range(top_k):\n",
    "                    close_word = reverse_dictionary[nearest[k]]\n",
    "                    log = '%s %s,' % (log, close_word)\n",
    "                print(log)\n",
    "    final_embeddings = normalized_embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_points = 400\n",
    "\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "two_d_embeddings = tsne.fit_transform(final_embeddings[1:num_points+1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot(embeddings, labels):\n",
    "    assert embeddings.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "    pylab.figure(figsize=(15,15))  # in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = embeddings[i,:]\n",
    "        pylab.scatter(x, y)\n",
    "        pylab.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')\n",
    "    pylab.show()\n",
    "\n",
    "words = [reverse_dictionary[i] for i in range(1, num_points+1)]\n",
    "plot(two_d_embeddings, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Function to generate a training batch for the skip-gram model.\n",
    "def generate_batch(batch_size, num_skips, skip_window):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1  # [ skip_window target skip_window ]\n",
    "    buffer = collections.deque(maxlen=span)\n",
    "    for _ in range(span):\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    for i in range(batch_size // num_skips):\n",
    "        target = skip_window  # target label at the center of the buffer\n",
    "        targets_to_avoid = [skip_window]\n",
    "        for j in range(num_skips):\n",
    "            while target in targets_to_avoid:\n",
    "                target = random.randint(0, span - 1)\n",
    "            targets_to_avoid.append(target)\n",
    "            batch[i * num_skips + j] = buffer[skip_window]\n",
    "            labels[i * num_skips + j, 0] = buffer[target]\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "    data_index = (data_index + len(data) - span) % len(data)\n",
    "    return batch, labels\n",
    "\n",
    "batch, labels = generate_batch(batch_size=8, num_skips=2, skip_window=1)\n",
    "for i in range(8):\n",
    "    print(batch[i], reverse_dictionary[batch[i]], '->', labels[i, 0], reverse_dictionary[labels[i, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "embedding_size = 128  # Dimension of the embedding vector.\n",
    "skip_window = 1       # How many words to consider left and right.\n",
    "num_skips = 2         # How many times to reuse an input to generate a label.\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors. Here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent.\n",
    "valid_size = 16     # Random set of words to evaluate similarity on.\n",
    "valid_window = 100  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "num_sampled = 64    # Number of negative examples to sample.\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "    # Ops and variables pinned to the CPU because of missing GPU implementation\n",
    "    with tf.device('/cpu:0'):\n",
    "        \n",
    "        # Look up embeddings for inputs.\n",
    "        embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "        embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "\n",
    "        # Construct the variables for the NCE loss\n",
    "        nce_weights = tf.Variable(tf.truncated_normal([vocabulary_size, embedding_size],stddev=1.0 / math.sqrt(embedding_size)))\n",
    "        nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "    # Compute the average NCE loss for the batch.\n",
    "    # tf.nce_loss automatically draws a new sample of the negative labels each\n",
    "    # time we evaluate the loss.\n",
    "    loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weights,\n",
    "                                         biases=nce_biases,\n",
    "                                         labels=train_labels,\n",
    "                                         inputs=embed,\n",
    "                                         num_sampled=num_sampled,\n",
    "                                         num_classes=vocabulary_size))\n",
    "\n",
    "    # Construct the SGD optimizer using a learning rate of 1.0.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "\n",
    "    # Compute the cosine similarity between minibatch examples and all embeddings.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "    similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "\n",
    "    # Add variable initializer.\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Step 5: Begin training.\n",
    "num_steps = 100001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    # We must initialize all variables before we use them.\n",
    "    init.run()\n",
    "    print(\"Initialized\")\n",
    "\n",
    "    average_loss = 0\n",
    "    for step in xrange(num_steps):\n",
    "        batch_inputs, batch_labels = generate_batch(batch_size, num_skips, skip_window)\n",
    "\n",
    "        # We perform one update step by evaluating the optimizer op (including it\n",
    "        # in the list of returned values for session.run()\n",
    "        _, loss_val = session.run([optimizer, loss], {train_inputs: batch_inputs, train_labels: batch_labels})\n",
    "        average_loss += loss_val\n",
    "\n",
    "        if step % 2000 == 0:\n",
    "            if step > 0:\n",
    "                average_loss /= 2000\n",
    "            # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "            print(\"Average loss at step \", step, \": \", average_loss)\n",
    "            average_loss = 0\n",
    "\n",
    "        # Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "        if step % 10000 == 0:\n",
    "            sim = similarity.eval()\n",
    "            for i in xrange(valid_size):\n",
    "                valid_word = reverse_dictionary[valid_examples[i]]\n",
    "                top_k = 8  # number of nearest neighbors\n",
    "                nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "                log_str = \"Nearest to %s:\" % valid_word\n",
    "                for k in xrange(top_k):\n",
    "                    close_word = reverse_dictionary[nearest[k]]\n",
    "                    log_str = \"%s %s,\" % (log_str, close_word)\n",
    "                print(log_str)\n",
    "    final_embeddings = normalized_embeddings.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "### Visualizer Functions\n",
    "These are some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plotter(history):\n",
    "    at, av, lt, lv = zip(*history)\n",
    "    fig = plt.figure(figsize=(15, 8)); ax1 = fig.add_subplot(221); ax2 = fig.add_subplot(222)\n",
    "\n",
    "    ax1.plot(np.arange(0, len(at), 1), at,\".-\", color='#2A6EA6', label=\"Training: {0:.2f}%\".format(at[-1]))\n",
    "    ax1.plot(np.arange(0, len(av), 1), av,\".-\", color='#FFA933', label=\"Validation: {0:.2f}%\".format(av[-1]))\n",
    "    ax1.grid(True); ax1.legend(loc=\"lower right\"); ax1.set_title(\"Accuracy per epoch\")\n",
    "\n",
    "    ax2.plot(np.arange(0, len(lt), 1), lt,\".-\", color='#2A6EA6', label=\"Training: {0:.2f}\".format(lt[-1]))\n",
    "    ax2.plot(np.arange(0, len(lv), 1), lv,\".-\", color='#FFA933', label=\"Validation: {0:.2f}\".format(lv[-1]))\n",
    "    ax2.grid(True); ax2.legend(loc=\"upper right\"); ax2.set_title(\"Cost per epoch\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "### Data Preproccessing\n",
    "Reformat into a TensorFlow-friendly shape:\n",
    "- all input should be numpy\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Training set:', twotfidf.shape, dataNL.label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = twotfidf.values\n",
    "labels = pd.get_dummies(dataNL.label).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Training set:', data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, validX, trainY, validY = train_test_split(data, labels, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Training set:', trainX.shape, trainY.shape)\n",
    "print('Validation set:', validX.shape, validY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "SIZE = trainX.shape[1]\n",
    "LABELS = 2\n",
    "BREAKS = 5\n",
    "BATCH = 64\n",
    "HIDDEN1 = 10\n",
    "RATE = 0.01\n",
    "STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    tfDataX = tf.placeholder(tf.float32, shape=(None, SIZE))\n",
    "    tfDataY = tf.placeholder(tf.float32, shape=(None, LABELS))\n",
    "\n",
    "    # Variables.\n",
    "    w1 = tf.Variable(tf.truncated_normal([SIZE, HIDDEN1], stddev=np.sqrt(2.0/SIZE)))\n",
    "    w2 = tf.Variable(tf.truncated_normal([HIDDEN1, LABELS], stddev=np.sqrt(2.0/SIZE)))\n",
    "    b1 = tf.Variable(tf.zeros([HIDDEN1]))\n",
    "    b2 = tf.Variable(tf.zeros([LABELS]))\n",
    "\n",
    "    # Model.\n",
    "    def model(x, training=False):\n",
    "        x = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "        return tf.matmul(x, w2) + b2\n",
    "  \n",
    "    # Training computation.\n",
    "    logits = model(tfDataX, training=True)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tfDataY))\n",
    "    rate = tf.train.exponential_decay(0.5, tf.Variable(0), 4000, 0.65, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(RATE).minimize(loss)\n",
    "\n",
    "    # Predictions and Accuracy.\n",
    "    predictions = {\"classes\": tf.argmax(model(tfDataX), axis=1),\"probabilities\": tf.nn.softmax(model(tfDataX))}\n",
    "    accuracy = tf.reduce_mean(tf.to_float(tf.equal(predictions[\"classes\"], tf.argmax(tfDataY, axis=1)))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    history = []\n",
    "    for step in range(STEPS):\n",
    "        offset = (step * BATCH) % (trainY.shape[0] - BATCH)\n",
    "        batchX = trainX[offset:(offset + BATCH), :]\n",
    "        batchY = trainY[offset:(offset + BATCH), :]\n",
    "        session.run(optimizer, {tfDataX: trainX, tfDataY: trainY})\n",
    "        if(step % (STEPS // BREAKS) == 0):\n",
    "            lt, at = session.run([loss, accuracy], {tfDataX: trainX, tfDataY: trainY})\n",
    "            lv, av = session.run([loss, accuracy], {tfDataX: validX, tfDataY: validY})\n",
    "            history.append((at, av, lt, lv))\n",
    "            print \".\",\n",
    "    predictions = session.run(predictions, {tfDataX: validX})\n",
    "    #accuracy = session.run(accuracy, {tfDataX: testX, tfDataY: testY})\n",
    "    #print('\\nTest accuracy: %.2f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plotter(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
